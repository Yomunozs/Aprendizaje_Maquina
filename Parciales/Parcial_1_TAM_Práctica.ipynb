{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "private_outputs": true,
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Yomunozs/Aprendizaje_Maquina/blob/main/Parciales/Parcial_1_TAM_Pr%C3%A1ctica.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "2 (Valor 2.5 puntos) Genere una simulacion sobre Python de los regresores por m ´ axima verosimilitud y m ´ aximo a-posteriori, discu- ´\n",
        "tidos en el punto 2.1, para ajustar la senal: ˜ tn = cos[xn/3] + cos[xn/4] + ηn, con xn ∈ [0, 24π], contaminada con ruido blanco\n",
        "Gaussiano ηn (SNRdB = 2[dB]). Asuma mapeo ϕ(·) del tipo polinomial de orden Q y prior p(w) = N (w|0, σ2\n",
        "w). Simule 500\n",
        "datos para entrenar los modelos y 200 para predecir. Incluya normalizacion por MinMaxScaler() de sklearn despu ´ es de generar el ´\n",
        "mapeo no lineal"
      ],
      "metadata": {
        "id": "UIthvRcbsoc3"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Se importan las liberias necesarias"
      ],
      "metadata": {
        "id": "TAN8sNbw6-mp"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "from sklearn.linear_model import Ridge\n",
        "from sklearn.preprocessing import PolynomialFeatures\n",
        "from sklearn.model_selection import ShuffleSplit\n",
        "from sklearn.preprocessing import MinMaxScaler\n",
        "from sklearn.preprocessing import PolynomialFeatures\n",
        "from sklearn.model_selection import train_test_split"
      ],
      "metadata": {
        "id": "JlBPqBm503sl"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Simuación de la señal"
      ],
      "metadata": {
        "id": "Qh7WI1BY7Ybg"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "xzefHzEBtQ7l"
      },
      "outputs": [],
      "source": [
        "N = 700 #Cantidad de datos\n",
        "x_n = np.linspace(0,24*np.pi,N) #Vector de datos en x\n",
        "t_n = np.cos(x_n/3)+np.cos(x_n/4) #Vector de datos en y sin ruido\n",
        "\n",
        "#función cálculo varianza del ruido a partir del snr dB\n",
        "def var_snr(x,snrdB): #x vector de datos (señal), snrdB SNR en dB\n",
        "    Px = np.mean(x**2)#estimador potencia media de la señal\n",
        "    return Px/(10**(snrdB/10)) #Calcuo de varianza del ruido\n",
        "snrdB = 2 #Relación seal/ruido\n",
        "var_r = var_snr(t_n,snrdB) #Varianza del ruido a partir de snrDB\n",
        "\n",
        "\n",
        "t_nr = t_n + np.sqrt(var_r)*np.random.randn(N) #Dtos de la señal contaminada con WGN\n",
        "\n",
        "#Se convierten los datos en vectores columna\n",
        "x_n = x_n.reshape(-1,1)#filas = realizaciones-muestras\n",
        "t_nr = t_nr.reshape(-1,1)\n",
        "\n",
        "\n",
        "#Grafica de la señal limpia y dispercion de la señal contaminada con WGN\n",
        "plt.figure(figsize = (5, 3))\n",
        "plt.plot(x_n, t_n, label='$t_n^*$', c='r', linewidth=2)\n",
        "plt.scatter(x_n, t_nr, c='b', label='$t_n$')\n",
        "plt.legend()\n",
        "plt.xlabel('x_n')\n",
        "plt.ylabel('t_n')\n",
        "plt.show()\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Mapeo no lineal"
      ],
      "metadata": {
        "id": "Vp2xyQcOAFaj"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#Division de datos por train_test_split()\n",
        "#x_train, x_test, t_train, t_test = train_test_split(x_n, t_nr,\n",
        "#                                                    test_size=200/N, random_state=42)\n",
        "\n",
        "#print(x_train.shape,x_test.shape,t_train.shape,t_test.shape)"
      ],
      "metadata": {
        "id": "V1K35Imcthge"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#generación representación polinomial, desde la libreria sklearn\n",
        "Q = 12 #grado del polinomio\n",
        "phiQ = PolynomialFeatures(degree=Q) # generar características polinomiales a partir de los  datos\n",
        "Phi_xn = phiQ.fit_transform(x_n)#representar datos desde polinomio\n"
      ],
      "metadata": {
        "id": "lo4-_JKyD8BY"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Division de datos con shuflesplit\n",
        "rs = ShuffleSplit(n_splits=1, random_state=0, test_size=0.2857) #200 de 700 equivale a  28,57 %\n",
        "for i, (x_train, x_test) in enumerate(rs.split(Phi_xn)):\n",
        "  print(i)\n",
        "\n",
        "#x_train/test, no llevan datos, solo indices\n",
        "\n"
      ],
      "metadata": {
        "id": "nzh2Vn5FL046"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Escalamiento de datos\n",
        "scaler = MinMaxScaler()\n",
        "Phi_xn[x_train] = scaler.fit_transform(Phi_xn[x_train])\n",
        "Phi_xn[x_test] = scaler.transform(Phi_xn[x_test])\n"
      ],
      "metadata": {
        "id": "E2l-nuPDtCnk"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Modelo de regresion y estimación MCR establecido en sklearn"
      ],
      "metadata": {
        "id": "a83atrLERZkh"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#regresor\n",
        "lambdaR = 1e-15#hiperparámetro de regularización\n",
        "reg_mc = Ridge(alpha=lambdaR) #Modelo de regresion ridge, L2, alpha ayuda  a evitar sobreajuste\n",
        "\n",
        "#Se ordenan los indices\n",
        "x_train = np.sort(x_train)\n",
        "x_test = np.sort(x_test)\n",
        "\n",
        "reg_mc.fit(Phi_xn[x_train],t_nr[x_train]) #Se entrena el modelo\n",
        "\n",
        "t_mc = reg_mc.predict(Phi_xn[x_test])# se prub el modelo con datos nuevos\n",
        "\n",
        "#Grafica de la señal limpia, dispercion de la señal contaminada con WGN y señal del predict\n",
        "plt.figure(figsize=(5,3))\n",
        "plt.plot(x_n,t_n,c='r',label='$t^*$')\n",
        "plt.scatter(x_n,t_nr,c='b',label='$t$')\n",
        "plt.plot(x_n[x_test],t_mc,c='g',label='$t_{mcr}$')\n",
        "\n",
        "plt.legend()\n",
        "plt.xlabel('x')\n",
        "plt.ylabel('t')\n",
        "plt.show()\n",
        "\n",
        "#raica de los pesos del regresor\n",
        "plt.figure(figsize=(5,3))\n",
        "plt.stem(reg_mc.coef_[0])\n",
        "plt.ylabel('pesos')\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "niD50ZyCzGSl"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#gráfica de varianza para ML:\n",
        "var_ml = (np.linalg.norm(t_nr[x_train]-reg_mc.predict(Phi_xn[x_train]))**2)/len(t_nr[x_train]) #Ecuacion de utiizando la predicción del regresor\n",
        "\n",
        "#Grafica de la variaza ajustada a la señal\n",
        "plt.figure(figsize=(5,3))\n",
        "plt.plot(x_n,t_n,c='r',label='$t$')\n",
        "plt.scatter(x_n,t_nr,c='y',label='$t+\\eta$')\n",
        "plt.plot(x_n[x_test],t_mc,c='g',label='$t_{*}$')\n",
        "plt.fill_between(x_n[x_test].ravel(), t_mc.ravel() - np.sqrt(var_ml)*np.ones(len(t_mc)),\n",
        "                t_mc.ravel() + np.sqrt(var_ml)*np.ones(len(t_mc)), alpha=0.8)\n",
        "\n",
        "plt.legend()\n",
        "plt.xlabel('x')\n",
        "plt.ylabel('t')\n",
        "plt.show()\n",
        "\n",
        "print(var_ml)"
      ],
      "metadata": {
        "id": "3j6dS74G5-t1"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Maxima verosimilitud manual"
      ],
      "metadata": {
        "id": "_G_44p5xU0i2"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#solución Maxima Verosimilitud\n",
        "\n",
        "#def my_ML(phi, t_n):\n",
        "#  w_ml = np.linalg.inv(phi.T.dot(phi) + lambdaR*np.eye(phi.shape[1])) @ phi.T @ t_n[x_train]\n",
        "#\n",
        "#  s_ml = (np.linalg.norm(t_nr[x_train]-reg_mc.predict(Phi_xn[x_train]))**2)/len(t_nr[x_train])\n",
        "#\n",
        "#\n",
        "#  return w_ml, s_ml\n",
        "\n",
        "\n",
        "#Solución por svd, valores propios\n",
        "\n",
        "#Funcionpara calcular los pesos y la varianza\n",
        "def regsvd(Phi,t,lambdaR=0,tol=1e-16):\n",
        "  S = Phi.T.dot(Phi) + lambdaR*np.eye(Phi.shape[1]) #Calculo de matriz S, coeficientes\n",
        "  val,vec = np.linalg.eigh(S) #valores propios de la matriz\n",
        "  #print(val.shape,vec.shape)\n",
        "  ind = val > tol #valores propios mayores a 0\n",
        "  Sinv = vec[:,ind].dot(np.diag(1/val[ind])).dot(vec[:,ind].T)# Se toma solo los valores mayores a cero\n",
        "  return Sinv.dot(Phi.T.dot(t)),val #Regresa pesos y valores propios\n",
        "\n",
        "#w, s = my_ML(Phi_xn[x_train], t_nr)\n",
        "w, s = regsvd(Phi_xn[x_train],t_nr[x_train],lambdaR = lambdaR) #Se calculan los valores de pesos y s con datos de entrenamiento\n",
        "phiN  = Phi_xn[x_test]#Se toman los datos nuevos que ya tienen la transformacion no lineal\n",
        "phiN = np.sort(phiN) #Se ordenan los datos por vector de indices\n",
        "tn =  Phi_xn[x_test] @ w #Se calcula el predict a partir de los pesos y los datos nuevos\n",
        "\n",
        "#Grafica de señal original contra la señal apartir de svd\n",
        "plt.figure(figsize=(5,3))\n",
        "plt.plot(x_n,t_n,c='r',label='$t^*$')\n",
        "plt.plot(x_n[x_test],tn,c='g',label='$t_{ml}$')\n",
        "\n",
        "plt.legend()\n",
        "plt.xlabel('x')\n",
        "plt.ylabel('t')\n",
        "plt.show()\n"
      ],
      "metadata": {
        "id": "FUcBD_HX0BnH"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "\n",
        "#def my_map():\n",
        "#return\n",
        "\n",
        "#..."
      ],
      "metadata": {
        "id": "-JSdXsoNw2c_"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "8lEzTmUPw-9m"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}